{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "33d38c97-b765-4e87-a866-e065742082d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18228270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elasticsearch is up at http://es01:9200.\n"
     ]
    }
   ],
   "source": [
    "ES_HOST = os.environ.get(\"ES_HOST\", \"http://es01:9200\")\n",
    "WORDS_FILE = \"/app/words.txt\"\n",
    "\n",
    "def wait_for_elasticsearch():\n",
    "    \"\"\" Wait until Elasticsearch is accessible on ES_HOST. \"\"\"\n",
    "    while True:\n",
    "        try:\n",
    "            r = requests.get(ES_HOST, timeout=3)\n",
    "            if r.status_code == 200:\n",
    "                print(f\"Elasticsearch is up at {ES_HOST}.\")\n",
    "                break\n",
    "        except requests.exceptions.RequestException:\n",
    "            pass\n",
    "        print(f\"Waiting for Elasticsearch to be ready at {ES_HOST}...\")\n",
    "        time.sleep(3)\n",
    "\n",
    "        \n",
    "wait_for_elasticsearch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f9ad41b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating the 'autocomplete' index with completion mapping...\n",
      "Index created or updated successfully.\n"
     ]
    }
   ],
   "source": [
    "def create_autocomplete_index():\n",
    "    \"\"\" Create the 'autocomplete' index with a 'completion' field mapping. \"\"\"\n",
    "    print(\"Creating the 'autocomplete' index with completion mapping...\")\n",
    "\n",
    "    # Define the mapping for the 'suggest' field\n",
    "    mapping = {\n",
    "        \"mappings\": {\n",
    "            \"properties\": {\n",
    "                \"suggest\": {\n",
    "                    \"type\": \"completion\"\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    url = f\"{ES_HOST}/autocomplete\"\n",
    "    # Use PUT to create or update index\n",
    "    response = requests.put(url, json=mapping)\n",
    "    if response.status_code in (200, 201):\n",
    "        print(\"Index created or updated successfully.\")\n",
    "    else:\n",
    "        # It's okay if index already exists; 400/404 can happen\n",
    "        print(f\"Index creation response ({response.status_code}): {response.text}\")\n",
    "\n",
    "create_autocomplete_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "98842a60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch [0:10000] indexed successfully.\n",
      "Batch [10000:20000] indexed successfully.\n",
      "Batch [20000:30000] indexed successfully.\n",
      "Batch [30000:40000] indexed successfully.\n",
      "Batch [40000:50000] indexed successfully.\n",
      "Batch [50000:60000] indexed successfully.\n",
      "Batch [60000:70000] indexed successfully.\n",
      "Batch [70000:80000] indexed successfully.\n",
      "Batch [80000:90000] indexed successfully.\n",
      "Batch [90000:100000] indexed successfully.\n",
      "Batch [100000:110000] indexed successfully.\n",
      "Batch [110000:120000] indexed successfully.\n",
      "Batch [120000:130000] indexed successfully.\n",
      "Batch [130000:140000] indexed successfully.\n",
      "Batch [140000:150000] indexed successfully.\n",
      "Batch [150000:160000] indexed successfully.\n",
      "Batch [160000:170000] indexed successfully.\n",
      "Batch [170000:180000] indexed successfully.\n",
      "Batch [180000:190000] indexed successfully.\n",
      "Batch [190000:200000] indexed successfully.\n",
      "Batch [200000:210000] indexed successfully.\n",
      "Batch [210000:220000] indexed successfully.\n",
      "Batch [220000:230000] indexed successfully.\n",
      "Batch [230000:240000] indexed successfully.\n",
      "Batch [240000:250000] indexed successfully.\n",
      "Batch [250000:260000] indexed successfully.\n",
      "Batch [260000:270000] indexed successfully.\n",
      "Batch [270000:280000] indexed successfully.\n",
      "Batch [280000:290000] indexed successfully.\n",
      "Batch [290000:300000] indexed successfully.\n",
      "Batch [300000:310000] indexed successfully.\n",
      "Batch [310000:320000] indexed successfully.\n",
      "Batch [320000:330000] indexed successfully.\n",
      "Batch [330000:340000] indexed successfully.\n",
      "Batch [340000:350000] indexed successfully.\n",
      "Batch [350000:360000] indexed successfully.\n",
      "Batch [360000:370000] indexed successfully.\n",
      "Batch [370000:380000] indexed successfully.\n",
      "Batch [380000:390000] indexed successfully.\n",
      "Batch [390000:400000] indexed successfully.\n",
      "Batch [400000:410000] indexed successfully.\n",
      "Batch [410000:420000] indexed successfully.\n",
      "Batch [420000:430000] indexed successfully.\n",
      "Batch [430000:440000] indexed successfully.\n",
      "Batch [440000:450000] indexed successfully.\n",
      "Batch [450000:460000] indexed successfully.\n",
      "Batch [460000:466550] indexed successfully.\n"
     ]
    }
   ],
   "source": [
    "def bulk_index_in_batches(words, batch_size=10000):\n",
    "    \"\"\"\n",
    "    Splits the 'words' list into chunks of 'batch_size' and \n",
    "    sends each chunk to the Elasticsearch Bulk API.\n",
    "    \"\"\"\n",
    "    def generate_bulk_payload(batch):\n",
    "        lines = []\n",
    "        for word in batch:\n",
    "            # Action/metadata\n",
    "            lines.append(json.dumps({\"index\": {\"_index\": \"autocomplete\"}}))\n",
    "            # Document body\n",
    "            lines.append(json.dumps({\"suggest\": word}))\n",
    "        return \"\\n\".join(lines) + \"\\n\"\n",
    "\n",
    "    total_docs = len(words)\n",
    "    start = 0\n",
    "\n",
    "    while start < total_docs:\n",
    "        end = min(start + batch_size, total_docs)\n",
    "        batch = words[start:end]\n",
    "        payload = generate_bulk_payload(batch)\n",
    "\n",
    "        # Send bulk\n",
    "        bulk_url = f\"{ES_HOST}/_bulk?refresh=wait_for\"\n",
    "        headers = {\"Content-Type\": \"application/x-ndjson\"}\n",
    "        response = requests.post(bulk_url, data=payload, headers=headers)\n",
    "\n",
    "        if response.status_code not in (200, 201):\n",
    "            print(f\"Batch [{start}:{end}] failed with status {response.status_code}\")\n",
    "            print(response.text)\n",
    "        else:\n",
    "            resp_json = response.json()\n",
    "            if resp_json.get(\"errors\"):\n",
    "                print(f\"Batch [{start}:{end}] had partial failures:\")\n",
    "                for item in resp_json.get(\"items\", []):\n",
    "                    if \"error\" in item[\"index\"]:\n",
    "                        print(json.dumps(item[\"index\"][\"error\"], indent=2))\n",
    "            else:\n",
    "                print(f\"Batch [{start}:{end}] indexed successfully.\")\n",
    "\n",
    "        start = end\n",
    "\n",
    "def index_words_in_batches():\n",
    "    if not os.path.isfile(WORDS_FILE):\n",
    "        print(\"No words.txt file found; skipping.\")\n",
    "        return\n",
    "\n",
    "    with open(WORDS_FILE, \"r\", encoding=\"utf-8\") as f:\n",
    "        words = [line.strip() for line in f if line.strip()]\n",
    "\n",
    "    # Here we choose 1000 as a default batch size; adjust to your needs\n",
    "    bulk_index_in_batches(words)\n",
    "\n",
    "# Then call:\n",
    "index_words_in_batches()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cc622d33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prefix: 'wo' -> Suggestions: ['WO', 'woa', 'woad', 'woad-leaved', 'woad-painted']\n",
      "Prefix: 'he' -> Suggestions: ['HE', 'he-all', 'he-balsam', 'he-broom', 'he-cabbage-tree']\n",
      "Prefix: 'wor' -> Suggestions: ['Worcester', 'Worcestershire', 'Word', 'worble', 'word-beat']\n",
      "Prefix: 'xyz' -> Suggestions: ['xyz']\n"
     ]
    }
   ],
   "source": [
    "def autocomplete(prefix):\n",
    "    \"\"\"\n",
    "    Send a suggest query to the 'autocomplete' index with the given prefix\n",
    "    and return a list of suggestion options.\n",
    "    \"\"\"\n",
    "    url = f\"{ES_HOST}/autocomplete/_search\"\n",
    "    headers = {\"Content-Type\": \"application/json\"}\n",
    "    \n",
    "    # Suggest query body\n",
    "    suggest_query = {\n",
    "        \"suggest\": {\n",
    "            \"word-suggest\": {\n",
    "                \"prefix\": prefix,\n",
    "                \"completion\": {\n",
    "                    \"field\": \"suggest\"\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    response = requests.post(url, headers=headers, json=suggest_query)\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Error fetching suggestions. Status: {response.status_code}\")\n",
    "        print(response.text)\n",
    "        return []\n",
    "    \n",
    "    data = response.json()\n",
    "    \n",
    "    # The suggest results are under data[\"suggest\"][\"word-suggest\"][0][\"options\"]\n",
    "    # We'll parse and return the suggested text.\n",
    "    suggestions = []\n",
    "    try:\n",
    "        suggest_items = data[\"suggest\"][\"word-suggest\"][0][\"options\"]\n",
    "        for item in suggest_items:\n",
    "            suggestions.append(item[\"text\"])\n",
    "    except (KeyError, IndexError):\n",
    "        print(\"Unexpected response format:\")\n",
    "        print(json.dumps(data, indent=2))\n",
    "    \n",
    "    return suggestions\n",
    "\n",
    "\n",
    "test_prefixes = [\"wo\", \"he\", \"wor\", \"xyz\"]\n",
    "\n",
    "for prefix in test_prefixes:\n",
    "    results = autocomplete(prefix)\n",
    "    print(f\"Prefix: '{prefix}' -> Suggestions: {results}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8498fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
